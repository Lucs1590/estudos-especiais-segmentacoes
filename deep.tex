\newpage
\section{Redes Neurais Profundas}

As redes neurais são modelos matemáticos inspirados no funcionamento do sistema nervoso de seres inteligentes, tal como o ser humano. As redes neurais são compostas por um conjunto de unidades menores interconectadas, chamadas de neurônio. Através da Figura 3.1, é possível visualizar uma ilustração dos componentes de um neurônio biológico.Este é conectado a diversos outros neurônios e realizam a comunicação por meio das sinapses.Este é conectado a diversos outros neurônios e realizam a comunicação por meio das sinapses.

O primeiro modelo matemático de neurônio artificial foi criado em 1943 por McCulloch e Pitts (1943) e pode ser visualizado através da Figura 3.2, sendo descrito matematicamente por (McCulloch e Pitts, 1943):

onde O representa a saída do neurônio, A(x) representa uma função de ativação A, x i representa a entrada i. Portanto, (x 1 , ..., x n ) são as entradas, fazendo analogia aos dendritos, ponderados pelos pesos (w 1 , ..., w n ). Por fim, b representa um viés (também chamado de bias). Através das Figuras 3.1 e

3.2 se observa que, analogamente, o corpo celular realiza a soma ponderada P das entradas N i=1 x i w i que residem nos dendritos e, combinada com um bias (ressalta-se que o bias não existe no modelo biológico, mas é necessário no modelo matemático), esta soma passa por uma função de ativação A, resutando em O = A( N i=1 x i w i + b) como saída do neurônio, ou seja, ao passar pelo axônio, a saída para outros neurônios é O.

A partir do modelo de neurônio da Figura 3.1, Rosenblatt (1958) propôs o modelo de neurônio chamado de Perceptron, em que a saída do neurônio é sempre uma saída binária, ou seja, a função de ativação é dada da forma (Rosenblatt, 1958)

Pode-se compreender que b representa o viés, determinando um limiar para a ativação do neurônio. O vetor x corresponde à entrada da rede e w é a matriz que corresponde aos pesos. A matriz de pesos deve ser inicializada randomicamente e, durante o treinamento da rede, estes valores são ajustados até se tornarem próximos do ideal.

Apesar do Perceptron conseguir resolver problemas como operações lógicas AND, OR e NAND, ele possui limitações em relação a resolver apenas problemas linearmente separáveis. O Perceptron não é capaz de gerar um hiperplano para separar problemas não lineares. A Figura 3.3 apresenta dois conjuntos, um primeiro demonstrando ser linearmente separável, significando que pode ser separado por uma linha, e outro conjunto não linearmente separável.

A partir do Perceptron, foi proposto o modelo mais simples de rede neural artificial denominado Multi Layer Perceptron (Werbos, 1974) ou MLP, composto por múltiplas camadas de Perceptron. Uma MLP consiste em três camadas de neurônios: uma camada de entrada, uma camada oculta e uma camada de saída, conforme a Figura 3.4. Com exceção da camada de entrada, cada neurônio utiliza uma função de ativação não linear. Dessa forma, o MLP é treinado através de uma técnica de aprendizado supervisionado denominada backpropagation (Rumelhart et al., 1986) (apresentada na Seção 3.2.3). Com a utilização de múltiplas camadas e funções de ativação não-lineares, a MLP é capaz de separar dados não linearmente separáveis.

Devido à necessidade de resolver problemas mais complexos, percebeu-se que adicionar mais camadas na MLP seria possível obter melhores resultados, a partir de uma base de dados maior e uma maior fase de treinamento. A partir de então, surge a área de redes neurais com aprendizado profundo (deep learning) (Goodfellow et al., 2016).

Segundo Ponti e Costa (2017), uma das principais ideias em deep learning é aprender representações intermediárias dos dados iterativamente, de forma que os algoritmos de aprendizado profundo aprendam os parâmetros a partir da entrada e definam cada representação como combinações de representações anteriores mais simples, em que cada camada opera sobre uma entrada gerando uma representação mais simples, que é então passada para a próxima camada (Goodfellow et al., 2016).

Recentemente, os métodos de aprendizado profundo têm se tornado o es tado da arte em diversas áreas, tendo como destaque a área de visão computacional. O sucesso recente se justifica por dois motivos, principalmente: pelo aumento na disponibilidade de grandes bases de imagens (Deng et al., 2009) e pela melhoria e barateamento do hardware, tornando possível computadores realizarem o processamento de grandes conjuntos de dados em tempo aceitável (Ponti e Costa, 2017).

Ao apresentar o funcionamento da MLP, foi utilizada uma função de ativação binária. Além dessa função de ativação, existem diversas funções de ativação descritas na literatura, onde cada uma é utilizada em um contexto específico.

Assim, no restante deste Capítulo, na Seção 3.1, serão apresentadas algumas funções de ativação descritas na literatura; na Seção 3.2, será discutido o processo de treinamento e, na Seção 3.3, a fase de teste.


\subsection{Funções de Ativação}

As funções de ativação definem como o valor computado pelo neurônio será transmitido para os próximos neurônios. O valor computado pelo neurônio P N 0 i=1 x i w i + b será definido por Y . A seguir, serão apresentadas as funções: limiar, linear, sigmóide, tanh, ReLU, leaky ReLU e sofmax. A Figura 3.5 apresenta os gráficos das respectivas funções de ativação.

Função Limiar : utiliza um valor limite (também chamado de threshold) γ, para determinar que valores acima de γ terão como saída 1 e, valores abaixo, como 0. A função de ativação utilizada para o Perceptron é uma função limiar onde γ = 0. A Equação 3.3 é definida matematicamente da forma (McCulloch e Pitts, 1943):

A função limiar é útil para problemas de classificação com 2 classes. Porém, para problemas multi-classes, torna difícil a convergência do modelo, por não garantir que apenas um único neurônio na camada de saída será ativado.

Função Linear: devido aos problemas apresentados pela função limiar, saídas contínuas podem facilitar a interpretação e superar o problema da função limiar. Uma alternativa simples é utilizar uma função de ativação linear, conforme descrito pela Equação 3.4 (Rosenblatt, 1958):

Um detalhe é que, ao utilizar uma função de ativação linear, os resultados serão lineares e, assim, a rede não será capaz de convergir em problemas não lineares.

Função Sigmóide: também chamada de função logística (Glorot et al.,2011), é uma função de ativação não-linear em que o valor resultante está presente no intervalo [0,1], sendo possível interpretar o resultado como probabilidade da saída do neurônio, dado pela Equação 3.5 (Glorot et al., 2011):

Quando há uma pequena variação no eixo x, a fase de aprendizado pode sofrer de um problema conhecido como Vanishing Gradient (Hochreiter, 1991) (Problema da Dissipação do Gradiente), implicando que os neurônios nas primeiras camadas irão aprender bem mais devagar quando comparado aos neurônios das últimas camadas, pois os valores de saída são muito pequenos, resultando em uma diminuição da acurácia do modelo ao longo do treinamento.

Função ReLU: a função rectified linear unit (Hahnloser et al., 2000), mais comumente chamada de ReLU, é geralmente utilizada entre as camadas ocultas da rede neural (Goodfellow et al., 2016). Sua função é dada pela Equação 3.7 (Hahnloser et al., 2000):

servindo como um assegurador que os resultados não serão negativos (Dahl et al., 2013). É uma função simples e fácil de otimizar, consequentemente, possui uma rápida convergência. Ela acelera a convergência do gradiente descendente estocástico, em comparação com a função sigmóide e tanh, além de não haver o problema da perda do gradiente.

Um ponto negativo é que, quando Y 0 > 0, o resultado está contido em [0, +∞), fazendo com que as saídas possíveis estejam em um intervalo extremamente grande. Dessa mesma forma, quando Y 0 ≤ 0, o valor resultante sempre é 0, dificultando a interpretação da rede neural em ambos os casos (Paula, 2020). Esse é um problema conhecido como dying ReLU.

Função Softmax: a função softmax faz dois cálculos: exponencia o valor recebido em cada neurônio e, então, normaliza este valor pela soma de todos os valores exponenciados recebidos de todos os neurônios, mapeando a saída para um intervalo de [0,1], fazendo com que a soma total seja sempre 1 (Kotu e Deshpande, 2018). Por causa desse comportamento, a saída da função é a distribuição de probabilidade da classe. Dado um problema de k-classes, softmax é computado pela Equação 3.9 (Kotu e Deshpande, 2018):

Assim, a função softmax é geralmente utilizada como função de ativação na camada de saída para problemas de multi-classificação, para determinar as probabilidades de cada classe.

As funções de ativação desempenham um papel fundamental para a convergência do modelo de redes neurais. Conforme apresentado pela literatura, tem-se como recomendação evitar usar sigmóide e tanh entre as camadas ocultas, tendo como padrão utilizar ReLU entre as camadas ocultas, pois ReLU e suas variações são baseadas no princípio de que os modelos de aprendizado profundo são fáceis de otimizar por seu comportamento ser próximo do linear (Goodfellow et al., 2016). A função de ativação na camada de saída depende da aplicação. Além das funções de ativação, há outros critérios que podem definir o sucesso do modelo, que serão apresentados na Seção seguinte.


\subsection{Treinamento}

Segundo Ponti e Costa (2017), a fase de treinamento envolve a tarefa de minimizar a função de custo ajustando os parâmetros da rede de forma iterativa, sendo cada passo realizado pela rede com uma única amostra chamado de iteração. As iterações por todo o conjunto de dados de treinamento é chamado de época. A cada iteração espera-se que o erro da rede sobre o conjunto de treinamento seja minimizado.

A Figura 3.6 apresenta resumidamente os passos realizados durante o treinamento de uma rede neural em uma época. A primeira etapa é a etapa de inicialização. Em seguida, seleciona uma amostra do conjunto de treinamento até que tenha se passado por todas as amostras do conjunto. Calcula-se a saída de cada camada da rede através da função de ativação em cada camada. Em seguida, calcula-se o erro na camada de saída por uma função de custo e o algoritmo backpropagation (junto com um algoritmo de otimização), modifica os pesos de cada camada da rede. A etapa de teste do resultado será abordada na Seção 3.3.

Tem-se como costume para a inicialização da rede, iniciar os pesos das camadas de maneira aleatória, e os hiper-parâmetros, como taxa de aprendizado, são definidos pelo usuário na etapa de inicialização. Nesta Seção, as funções de custo serão discutidas na Seção 3.2.1, responsáveis por indicar o resultado da rede sobre o conjunto de treinamento. Em seguida, as funções de otimização são apresentadas na Seção 3.2.2, responsáveis pela convergência do modelo. Por fim, o algoritmo backpropagation é descrito na Seção 3.2.3, responsável por propagar o erro para as camadas internas da rede.


\subsubsection{Função de Custo}

Para que se possa realizar o treinamento, é necessário que haja uma maneira de computar se o resultado obtido pela rede é um bom resultado ou não. Ou seja, é necessária uma maneira de avaliar se a rede está convergindo ou não. As funções responsáveis por inferir a qualidade da predição são chamadas de função de custo, ou loss function. Esta função calcula o quão perto o modelo está da resposta adequada.

Para problemas de regressão, como é o caso de filtragem de ruído usando aprendizado profundo, a loss function pode ser calculada a partir da métrica erro quadrático médio (ou Mean Squared Error, MSE) (Wang et al., 2004). No caso de filtragem de ruído, em alguns casos, a saída da rede neural é a imagem sem ruído e, a partir dessa imagem, calcula-se o MSE sobre cada pixel existente entre a imagem predita ŷ (obtida pela saída da rede) e a imagem original y. Seja M × N as dimensões da imagem, o MSE é dado por:

\subsubsection{\textit{Backpropagation}}
O algoritmo backpropagation foi proposto por Rumelhart et al. (1986), e foi responsável por permitir a criação de modelos de redes neurais profundas, por apresentar um processo de reajustar os pesos das camadas ocultas. A partir da saída da rede y, calcula-se o erro considerando uma função de custo (apresentada na Seção 3.2.1). Em seguida, o erro é propagado, da camada oculta em direção à camada de entrada, por meio da combinação do algoritmo backpropagation e de um algoritmo de otimização (apresentado na Seção 3.2.2), onde o backpropagatipn é utilizado para um cálculo rápido de gradientes que são utilizados pelos algoritmos de otimização.

Seja E o erro obtido a partir da saída da rede y em relação a d (ground truth). O primeiro passo é computar a derivada parcial de E em relação a cada um, sendo i ∈ K, onde K são os neurônios dos neurônios de saída, da forma: ∂ ∂E y ˆ i de saída. Ao aplicar a regra da cadeia de E em relação às entradas x j , tem-se que (Rumelhart et al., 1986):

Segundo Rumelhart et al. (1986), ∂x indica o quanto alterar a entrada x irá j afetar o erro na saída. Como a entrada é uma função linear de pesos nas conexões, o cálculo do quanto o erro é afetado ao alterar os pesos da conexão do neurônio j com o neurônio i, é dado pela derivada parcial (Rumelhart etal., 1986):

e, levando em consideração as conexões do neurônio i, tem-se que (Rumelhart et al., 1986):

Dessa forma, é possível definir ∂E dos neurônios da camada t, quando ∂y dos neurônios da camada t − 1 já houverem sido definidos.


\subsection{Teste}

A etapa de teste envolve avaliar o modelo treinado sobre um novo conjunto de dados desconhecido, com a finalidade de avaliar a capacidade de generalização do modelo. Por isso, o conjunto de dados é dividido entre conjunto de treinamento e conjunto de teste, sendo uma menor parcela geralmente alocada para teste (Goodfellow et al., 2016). É necessário que ambos os conjuntos de dados possuam uma mesma distribuição dos dados, por exemplo: suponha que o conjunto de dados C possua um total de 100 imagens, contendo fotos de gatos e cachorros, sendo que 50 das 100 imagens são de gatos e o restante de cachorros. O conjunto de teste pode ser 20\% do conjunto total, portanto 20 imagens. As 20 imagens do conjunto de teste devem ser 10 imagens de gato e 10 de cachorro, consequentemente. O mesmo equivale para o conjunto de treinamento, onde se espera que a distribuição dos dados em treinamento seja uma distribuição similar em teste.

O processo de teste pode ser realizado a cada época, ou seja, cada vez que a rede é apresentada ao conjunto de treinamento, avalia-se o seu desempenho em um conjunto desconhecido. Ao longo das épocas, é possível avaliar se a rede está ou não melhorando a capacidade de generalização.

Diversas técnicas tem sido propostas na literatura para auxiliar a etapa de teste sobre um conjunto desconhecido, tendo como objetivo que o teste seja feito de maneira não enviesada. Assim, na Seção 3.3.1, as métricas de avaliação são apresentadas; na Seção 3.3.2, o algoritmo cross validation é apresentado; na Seção 3.3.3, é discorrido sobre os fenômenos overfitting e underfitting.


\subsubsection{Métricas de Avaliação}

As métricas de avaliação ou funções de performance são responsáveis por avaliar o desempenho do algoritmo, tanto no conjunto de treinamento como no conjunto de teste. Ou seja, são responsáveis por avaliar se um algoritmo está obtendo bons resultados em relação ao conjunto de treinamento, e em relação ao conjunto de teste. Para problemas de classificação, geralmente se utiliza como métrica de avaliação a acurácia Acc, que é a razão entre o número de predições corretas em relação ao total de amostras no conjunto, dado pela Equação 3.27:

A acurácia possui um resultado adequado para quando há um conjunto de dados balanceado entre classes, porém apresenta problemas ao lidar com desbalanceamento de classes. Considerando o caso de classes balanceadas, tem-se como objetivo que Acc train ≈ Acc test e que ambas as acurácias sejam valores altos. Em casos que Acc train e Acc test apresentam valores altos e baixos, respectivamente, e Acc test baixos, correpondem a casos de overfitting. Porém, quando Acc train possui valores baixos, corresponde a situação de underfitting. Maiores detalhes sobre overfitting e underfitting serão apresentados detalhadamente na Seção 3.3.3.

Para cenários de regressão, é comum utilizar o MSE (erro quadrático médio) como métrica, propondo também minimizar a distância entre M SE train e M SE test . Para o contexto de filtragem de ruído, costuma-se utilizar como métrica de avaliação aquelas apresentadas na Seção 2.4, em que as mais comunssão a PSNR e a SSIM. Dessa forma, busca-se maximizar P SN R test conforme P SN R train aumenta. Para casos em que P SN R train cresce, mas P SN R test diminui, é detectado um cenário de overfitting, descrito com mais detalhes em 3.3.3. Portanto, P SN R train ≈ P SN R test indica que ambos os conjuntos seguem uma distribuição parecida.


\subsubsection{Validação Cruzada}

Dividir o conjunto de dados entre um conjunto fixo de treinamento e um conjunto fixo de teste implica em uma incerteza estatística sobre a média estimada de erro do teste, pois os conjuntos podem estar desbalanceados (Goodfellow et al., 2016). A validação cruzada (ou cross validation), é baseada na ideia de repetidamente computar o treinamento e teste para subconjuntos de treinamento e teste aleatórios e diferentes em cada iteração, sendo resultado da divisão do conjunto de dados original. Ou seja, para cada passo, divide-se aleatoriamente o conjunto de dados original em treinamento e teste, e para o passo seguinte, é realizada novamente a divisão.

Dessa forma, o erro do teste pode ser estimado pela média dos erros sobre todos os passos, conforme a Equação 3.28:

sendo ε T o erro estimado do teste T , ε i o erro de teste no passo i e N a quantidade de passos executado.

\subsubsection{\textit{Overfitting} e \textit{Underfitting}}
Um modelo com viés alto significa que o modelo não está aprendendo com os dados de treinamento, levando a erros altos tanto em relação aos dados de treinamento como de teste, o que também pode ser chamado de underfitting (sub-ajuste). Por outro lado, quando um modelo possui uma variância alta, significa que o modelo possui um erro baixo em relação ao conjunto de dados de treinamento, porém o modelo não é capaz de generalizar - por esse motivo, costuma-se dizer que o modelo apenas decorou os dados. Como resultado, o modelo possui uma taxa alta de erro nos dados de teste, o que também pode ser chamado como overfitting (sobre-ajuste).

A Figura 3.7 apresenta uma maneira gráfica de compreender ambos os fenômenos. É possível perceber que o underfitting é causado pelo fato da função de aproximação f ser muito simples para o problema apresentado - ou seja, o problema é não linear, enquanto que se tentou aproximar do resultado por meio de um método linear. No segundo gráfico, conseguiu-se chegar em um resultado razoável para a distribuição dos dados, da qual a função aproximada se apresenta como uma função não linear e provavelmente irá generalizar para outras instâncias do conjunto, desde que tenham o mesmo comportamento. Para o terceiro gráfico, é um caso de overfitting, pois a função se ajustou muito bem aos dados de treinamento, porém perdeu a capacidade de generalização. Isso ocorre quando se utiliza um método com um grau de complexidade muito grande para problemas simples, por exemplo, considerando o método de redes neurais, seria como aplicar uma rede neural com muitas camadas para problemas que deveriam usar poucas camadas.

Uma maneira prática de se perceber casos de overfitting ou underfitting é utilizar um gráfico de linhas com a função de custo tanto da etapa de treinamento como de teste. A Figura 3.8 apresenta um exemplo de overfitting. A partir do momento em que a função de custo de treinamento continua a decrementar e a função de custo de teste começa a aumentar, é o ponto de início do overfitting, então seria o melhor momento para se encerrar o treinamento. Para caso de underfitting, ocorre quando ambas as funções de custo permanecem altas mesmo após muitas épocas.

Portanto, casos de underfitting e overfitting devem ser percebidos e corrigidos, dado o método utilizado. Atualmente, para ajustar o método à complexidade do problema, ainda se utiliza tentativa e erro e se utilizam gráficos como o apresentado na Figura 3.8 para detectar ambos os fenômenos (Goodfellow et al., 2016).


\subsection{Redes Neurais Convolucionais}
\label{deep:CNN}
\begin{itemize}
    \item Ler site (https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/) para pegar as referencias de cada seção;
    \item citar \cite{Minaee2021};
    \item citar \cite{Parkhi2015};
    \item citar \cite{Ghosh2019}.
\end{itemize}

As redes neurais convolucionais, também chamadas como CNN (Convolutional Neural Networks) (LeCun et al., 1999) são o tipo de rede neural mais comum na literatura e tem sido amplamente aplicadas para problemas de visão computacional. Elas possuem este nome por conterem camadas convolucionais e são especializadas em processar dados espaciais, tais como imagens (Ponti e Costa, 2017, Goodfellow et al., 2016).

Talvez, estas correspondam ao maior sucesso da história de inteligência artificial inspirada biologicamente (Goodfellow et al., 2016). As CNNs capturam importantes propriedades do córtex visual primário localizado no cérebro, também chamado de V1, que é responsável por processar os impulsos visuais. Algumas propriedades inspiram as redes neurais artificiais, como o arranjo espacial, as células complexas receberem as características detectadas pelas células mais simples, as células complexas serem pequenas mudanças na posição das características. Estas características inspiraram a operação de pooling em redes convolucionais (Goodfellow et al., 2016).

Além do sucesso na inspiração do modelo biológico, as CNNs são um exemplo de sucesso na aplicação no contexto comercial e permanecem à frente de aplicações de aprendizado profundo atualmente (Goodfellow et al., 2016). No fim dos anos de 1990, um sistema baseado em CNNs desenvolvido para ler cheques manuscritos já era responsável por ler cerca de 10\% de todos os cheques dos Estados Unidos (Goodfellow et al., 2016).


\subsubsection{Camada Convolucional}

Segundo Ponti e Costa (2017), cada neurônio na camada convolucional é um filtro aplicado à imagem de entrada, sendo cada filtro uma matriz de pesos e a operação de convolução um tipo de operação linear (Goodfellow et al., 2016).

A Figura 3.9 apresenta um exemplo gráfico de convolução, aplicado em uma imagem com um kernel 2 × 2. Primeiro, a operação de convolução é aplicada nos pixels a, b, c e f , formando a primeira saída na posição (0, 0). Em seguida, a operação de convolução é aplicada em b, c, f e g deslocando-se uma posição à direita, sendo esse deslocamento também chamado de stride (ou passo), resultando na saída na posição (0, 1). Ao final do eixo x, a operação se desloca uma posição para baixo, retornando também à coluna inicial, continuando até o fim da imagem, resultando em uma imagem de dimensão 2 × 3.

O resultado de um filtro convolucional é chamado de mapa de características ou feature map. Nas camadas convolucionais, cada camada é composta por N filtros convolucionais, das quais os mapas de características gerados por cada um dos filtros são empilhados e também chamados de tensor (Ponti e Costa, 2017). Portanto, a entrada para a camada c + 1 é o tensor composto pelos mapas de características gerados na camada c.


\subsubsection{Camada de \textit{Pooling}}

As camadas de pooling são atualmente empregadas nas redes neurais para reduzir o tempo de treinamento. Estas camadas tem o propósito de reduzir a dimensionalidade do mapa de características ao longo da rede. A Figura 3.10 exemplifica o funcionamento de uma camada de max pooling. O mapa de características possui dimensão 3 × 4 e a janela deslizante é uma janela 2 × 2. Considerando o stride = 1, a janela irá aplicar a operação de max a cada iteração, deslocando 1 passo por vez, gerando como resultado um mapa de características de tamanho 2 × 3. Outras funções de pooling também são utilizadas, como o average pooling, median pooling e weighted average (este baseado na distância do pixel central) (Goodfellow et al., 2016).


\subsubsection{\textit{Dropout}}

A operação de dropout (Srivastava et al., 2014) tem sido empregada ao longo da rede para prevenir o overfitting (Goodfellow et al., 2016). A técnica consiste em desligar aleatoriamente alguns neurônios das camadas ocultas durante o treinamento. Dessa forma, tende-se que cada neurônio da camada oculta seja útil para geração da saída, reduzindo a influência de neurônios enviesados. O dropout não é aplicado durante a etapa de teste.

\subsubsection{Camada de Saída}

Após várias camadas de convolução e preenchimento, precisaríamos da saída na forma de uma classe. As camadas de convolução e pooling seriam capazes apenas de extrair recursos e reduzir o número de parâmetros das imagens originais. No entanto, para gerar a saída final, precisamos aplicar uma camada totalmente conectada para gerar uma saída igual ao número de classes que precisamos. Torna-se difícil atingir esse número apenas com as camadas de convolução. Camadas de convolução geram mapas de ativação 3D enquanto nós apenas precisamos da saída para saber se uma imagem pertence ou não a uma classe particular. A camada de saída tem uma função de perda, como entropia cruzada categórica, para calcular o erro na previsão. Depois que o passe para frente é concluído, a backpropagation começa a atualizar o peso e as tendências para erro e redução de perda.